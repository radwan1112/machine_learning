{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdecdc00-3b0c-4615-8d01-1e36be47af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7dbb3-48da-499f-9c3d-e6cdbe27d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'data/train/'\n",
    "VALIDATION_DATA_DIR = 'data/val/'\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bc6b5-4cff-44de-a5ac-df88ebf46f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                  rotation_range = 20,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  zoom_range = 0.2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945fa1f-64cb-4a49-9591-8b1494c0b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                   target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                   batch_size = BATCH_SIZE,\n",
    "                                                   shuffle = True,\n",
    "                                                   seed = 12345,\n",
    "                                                   class_mode  = 'categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(VALIDATION_DATA_DIR,\n",
    "                                                      target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      shuffle = False,\n",
    "                                                      class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a53ff9-9912-4c7e-8b0a-679110150ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        # Freeze the layers of the base model\n",
    "        layer.trainable = False \n",
    "    \n",
    "    input = Input(shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation = 'relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation = 'softmax')(custom_model)\n",
    "    \n",
    "    return Model(inputs = input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c068f-c46b-4c97-9c5a-1611500486d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "num_steps = math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE)\n",
    "\n",
    "model.fit(train_generator,\n",
    "                   steps_per_epoch = num_steps,\n",
    "                   epochs = 10,\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725e03d-0ce3-4c85-8cf9-61e8186a54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b804de-e54e-4e41-8d27-127f1bcfb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0f200-4935-4324-96c6-7f0b3f021e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../sample-images/dog.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis = 0)\n",
    "preprocessed_img = preprocess_input(expanded_img_array)\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d7f71-0133-4318-84d6-c07b7c7cda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7fc5d-b10b-4dfb-a728-22c012c2cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../sample-images/dog.jpg'\n",
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis = 0)\n",
    "preprocessed_img = preprocess_input(expanded_img_array)\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649cdc1-ca0c-41f8-815b-4e7df565c6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-imgclassify]",
   "language": "python",
   "name": "conda-env-.conda-imgclassify-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
